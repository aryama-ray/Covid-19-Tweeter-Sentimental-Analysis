{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DataLoader.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aryama-ray/Covid-19-Tweeter-Sentimental-Analysis/blob/main/DataLoader.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PDRMQ83g5JRV"
      },
      "source": [
        "import torch\r\n",
        "import torchvision\r\n",
        "from torch.utils.data import Dataset, DataLoader\r\n",
        "import numpy as np\r\n",
        "import math"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZmKYjT616Vc8"
      },
      "source": [
        "# gradient computation etc. not efficient for whole data set\r\n",
        "# -> divide dataset into small batches\r\n",
        "\r\n",
        "'''\r\n",
        "# training loop\r\n",
        "for epoch in range(num_epochs):\r\n",
        "    # loop over all batches\r\n",
        "    for i in range(total_batches):\r\n",
        "        batch_x, batch_y = ...\r\n",
        "'''\r\n",
        "\r\n",
        "# epoch = one forward and backward pass of ALL training samples\r\n",
        "# batch_size = number of training samples used in one forward/backward pass\r\n",
        "# number of iterations = number of passes, each pass (forward+backward) using [batch_size] number of sampes\r\n",
        "# e.g : 100 samples, batch_size=20 -> 100/20=5 iterations for 1 epoch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vagAcdPG6ZLC"
      },
      "source": [
        "# --> DataLoader can do the batch computation for us\r\n",
        "\r\n",
        "# Implement a custom Dataset:\r\n",
        "# inherit Dataset\r\n",
        "# implement __init__ , __getitem__ , and __len__\r\n",
        "\r\n",
        "class WineDataset(Dataset):\r\n",
        "\r\n",
        "    def __init__(self):\r\n",
        "        # Initialize data, download, etc.\r\n",
        "        # read with numpy or pandas\r\n",
        "        xy = np.loadtxt('./data/wine/wine.csv', delimiter=',', dtype=np.float32, skiprows=1)\r\n",
        "        self.n_samples = xy.shape[0]\r\n",
        "\r\n",
        "        # here the first column is the class label, the rest are the features\r\n",
        "        self.x_data = torch.from_numpy(xy[:, 1:]) # size [n_samples, n_features]\r\n",
        "        self.y_data = torch.from_numpy(xy[:, [0]]) # size [n_samples, 1]\r\n",
        "\r\n",
        "    # support indexing such that dataset[i] can be used to get i-th sample\r\n",
        "    def __getitem__(self, index):\r\n",
        "        return self.x_data[index], self.y_data[index]\r\n",
        "\r\n",
        "    # we can call len(dataset) to return the size\r\n",
        "    def __len__(self):\r\n",
        "        return self.n_samples\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TutTBxnL6dXj"
      },
      "source": [
        "# create dataset\r\n",
        "dataset = WineDataset()\r\n",
        "\r\n",
        "# get first sample and unpack\r\n",
        "first_data = dataset[0]\r\n",
        "features, labels = first_data\r\n",
        "print(features, labels)\r\n",
        "\r\n",
        "# Load whole dataset with DataLoader\r\n",
        "# shuffle: shuffle data, good for training\r\n",
        "# num_workers: faster loading with multiple subprocesses\r\n",
        "# !!! IF YOU GET AN ERROR DURING LOADING, SET num_workers TO 0 !!!\r\n",
        "train_loader = DataLoader(dataset=dataset,\r\n",
        "                          batch_size=4,\r\n",
        "                          shuffle=True,\r\n",
        "                          num_workers=2)\r\n",
        "\r\n",
        "# convert to an iterator and look at one random sample\r\n",
        "dataiter = iter(train_loader)\r\n",
        "data = dataiter.next()\r\n",
        "features, labels = data\r\n",
        "print(features, labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ba4cEDKI6g4D"
      },
      "source": [
        "# Dummy Training loop\r\n",
        "num_epochs = 2\r\n",
        "total_samples = len(dataset)\r\n",
        "n_iterations = math.ceil(total_samples/4)\r\n",
        "print(total_samples, n_iterations)\r\n",
        "for epoch in range(num_epochs):\r\n",
        "    for i, (inputs, labels) in enumerate(train_loader):\r\n",
        "        \r\n",
        "        # here: 178 samples, batch_size = 4, n_iters=178/4=44.5 -> 45 iterations\r\n",
        "        # Run your training process\r\n",
        "        if (i+1) % 5 == 0:\r\n",
        "            print(f'Epoch: {epoch+1}/{num_epochs}, Step {i+1}/{n_iterations}| Inputs {inputs.shape} | Labels {labels.shape}')\r\n",
        "\r\n",
        "# some famous datasets are available in torchvision.datasets\r\n",
        "# e.g. MNIST, Fashion-MNIST, CIFAR10, COCO\r\n",
        "\r\n",
        "train_dataset = torchvision.datasets.MNIST(root='./data', \r\n",
        "                                           train=True, \r\n",
        "                                           transform=torchvision.transforms.ToTensor(),  \r\n",
        "                                           download=True)\r\n",
        "\r\n",
        "train_loader = DataLoader(dataset=train_dataset, \r\n",
        "                                           batch_size=3, \r\n",
        "                                           shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zg3XVdBa6k25"
      },
      "source": [
        "# look at one random sample\r\n",
        "dataiter = iter(train_loader)\r\n",
        "data = dataiter.next()\r\n",
        "inputs, targets = data\r\n",
        "print(inputs.shape, targets.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zHug9opq6nAp"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}